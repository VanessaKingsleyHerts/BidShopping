{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c7ad88-d2fd-414e-91e2-7839298fd947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe5d29c-137b-45ff-a212-13dab4659929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'command', 'duration_s', 'exit_code', 'cpu_pct_avg',\n",
      "       'mem_kb_max', 'tag', 'status', 'pipeline_id', 'mode'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>command</th>\n",
       "      <th>duration_s</th>\n",
       "      <th>exit_code</th>\n",
       "      <th>cpu_pct_avg</th>\n",
       "      <th>mem_kb_max</th>\n",
       "      <th>tag</th>\n",
       "      <th>status</th>\n",
       "      <th>pipeline_id</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-15 07:17:52</td>\n",
       "      <td>docker login -u \"gitlab-ci-token\" -p \"glcbt-ey...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>pass</td>\n",
       "      <td>1.870500e+09</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-15 07:19:14</td>\n",
       "      <td>docker build -t \"registry.gitlab.com/uhthesis/...</td>\n",
       "      <td>82.14</td>\n",
       "      <td>0</td>\n",
       "      <td>40.59</td>\n",
       "      <td>46396</td>\n",
       "      <td>unknown</td>\n",
       "      <td>pass</td>\n",
       "      <td>1.870500e+09</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-15 07:20:06</td>\n",
       "      <td>docker push \"registry.gitlab.com/uhthesis/bids...</td>\n",
       "      <td>51.59</td>\n",
       "      <td>0</td>\n",
       "      <td>55.48</td>\n",
       "      <td>37844</td>\n",
       "      <td>unknown</td>\n",
       "      <td>pass</td>\n",
       "      <td>1.870500e+09</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06-15 07:21:05</td>\n",
       "      <td>flake8 .</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>48.15</td>\n",
       "      <td>22600</td>\n",
       "      <td>unknown</td>\n",
       "      <td>pass</td>\n",
       "      <td>1.870500e+09</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-15 07:22:02</td>\n",
       "      <td>python manage.py collectstatic --noinput</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>35.40</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>pass</td>\n",
       "      <td>1.870500e+09</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                                            command  \\\n",
       "0  2025-06-15 07:17:52  docker login -u \"gitlab-ci-token\" -p \"glcbt-ey...   \n",
       "1  2025-06-15 07:19:14  docker build -t \"registry.gitlab.com/uhthesis/...   \n",
       "2  2025-06-15 07:20:06  docker push \"registry.gitlab.com/uhthesis/bids...   \n",
       "3  2025-06-15 07:21:05                                           flake8 .   \n",
       "4  2025-06-15 07:22:02           python manage.py collectstatic --noinput   \n",
       "\n",
       "   duration_s  exit_code  cpu_pct_avg  mem_kb_max      tag status  \\\n",
       "0        0.50          0         6.10           0  unknown   pass   \n",
       "1       82.14          0        40.59       46396  unknown   pass   \n",
       "2       51.59          0        55.48       37844  unknown   pass   \n",
       "3        1.00          0        48.15       22600  unknown   pass   \n",
       "4        0.50          0        35.40           0  unknown   pass   \n",
       "\n",
       "    pipeline_id      mode  \n",
       "0  1.870500e+09  baseline  \n",
       "1  1.870500e+09  baseline  \n",
       "2  1.870500e+09  baseline  \n",
       "3  1.870500e+09  baseline  \n",
       "4  1.870500e+09  baseline  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the full CI logs dataset\n",
    "df = pd.read_csv(\"../data/all_logs.csv\")\n",
    "\n",
    "# Normalize column names to lowercase\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# Preview structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993b0a0f-70e7-470a-83cc-649b2e639808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cpu_pct_avg</th>\n",
       "      <th>status</th>\n",
       "      <th>pipeline_id</th>\n",
       "      <th>mode</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>mem_mb</th>\n",
       "      <th>log_duration</th>\n",
       "      <th>tag_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-15 07:17:52</td>\n",
       "      <td>6.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.870500e+09</td>\n",
       "      <td>baseline</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-15 07:19:14</td>\n",
       "      <td>40.59</td>\n",
       "      <td>1</td>\n",
       "      <td>1.870500e+09</td>\n",
       "      <td>baseline</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>45.308594</td>\n",
       "      <td>4.420526</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-15 07:20:06</td>\n",
       "      <td>55.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1.870500e+09</td>\n",
       "      <td>baseline</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>36.957031</td>\n",
       "      <td>3.962526</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06-15 07:21:05</td>\n",
       "      <td>48.15</td>\n",
       "      <td>1</td>\n",
       "      <td>1.870500e+09</td>\n",
       "      <td>baseline</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>22.070312</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-15 07:22:02</td>\n",
       "      <td>35.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.870500e+09</td>\n",
       "      <td>baseline</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  cpu_pct_avg  status   pipeline_id      mode  hour  \\\n",
       "0 2025-06-15 07:17:52         6.10       1  1.870500e+09  baseline     7   \n",
       "1 2025-06-15 07:19:14        40.59       1  1.870500e+09  baseline     7   \n",
       "2 2025-06-15 07:20:06        55.48       1  1.870500e+09  baseline     7   \n",
       "3 2025-06-15 07:21:05        48.15       1  1.870500e+09  baseline     7   \n",
       "4 2025-06-15 07:22:02        35.40       1  1.870500e+09  baseline     7   \n",
       "\n",
       "   dayofweek     mem_mb  log_duration  tag_code  \n",
       "0          6   0.000000      0.405465         3  \n",
       "1          6  45.308594      4.420526         3  \n",
       "2          6  36.957031      3.962526         3  \n",
       "3          6  22.070312      0.693147         3  \n",
       "4          6   0.000000      0.405465         3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns we don't want\n",
    "df = df.drop(columns=[\"command\", \"exit_code\"])\n",
    "\n",
    "# Convert timestamp\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n",
    "\n",
    "# Drop timestamp if you don't need time-series modeling\n",
    "# df = df.drop(columns=[\"timestamp\"])\n",
    "\n",
    "# Convert memory to MB\n",
    "df[\"mem_mb\"] = df[\"mem_kb_max\"] / 1024\n",
    "df.drop(columns=[\"mem_kb_max\"], inplace=True)\n",
    "\n",
    "# Log-transform duration\n",
    "df[\"log_duration\"] = np.log1p(df[\"duration_s\"])\n",
    "df.drop(columns=[\"duration_s\"], inplace=True)\n",
    "\n",
    "# Encode tag (CI stage)\n",
    "df[\"tag_code\"] = df[\"tag\"].astype(\"category\").cat.codes\n",
    "df.drop(columns=[\"tag\"], inplace=True)\n",
    "\n",
    "# Encode target\n",
    "df[\"status\"] = df[\"status\"].map({\"pass\": 1, \"fail\": 0})\n",
    "\n",
    "# Final preview\n",
    "df.head()\n",
    "\n",
    "# result - 6 columns representing the 6 input features\n",
    "# tag column refers to the CI job type - 0 = build, 1 = lint, 2 = test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d60af87-6e2f-4862-a34d-15ad37f8a899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X:\n",
      " log_duration    0\n",
      "cpu_pct_avg     0\n",
      "mem_mb          0\n",
      "tag_code        0\n",
      "hour            0\n",
      "dayofweek       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((309, 6), (78, 6))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features for model (exclude pipeline_id!)\n",
    "features = [\"log_duration\", \"cpu_pct_avg\", \"mem_mb\", \"tag_code\", \"hour\", \"dayofweek\"]\n",
    "X = df[features]\n",
    "y = df[\"status\"]\n",
    "\n",
    "print(\"NaNs in X:\\n\", X.isnull().sum())\n",
    "\n",
    "mask = X.notnull().all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# result - example: ((231, 6), (58, 6)) = 231 samples in the training set, 58 samples in the test set, Each with 6 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2336e158-4db2-4be8-808b-6f3bc9c7c783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.24      1.00      0.39        10\n",
      "        pass       1.00      0.54      0.70        68\n",
      "\n",
      "    accuracy                           0.60        78\n",
      "   macro avg       0.62      0.77      0.55        78\n",
      "weighted avg       0.90      0.60      0.66        78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight=\"balanced\", max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Performance\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=[\"fail\", \"pass\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "066fcb33-5738-4749-945c-0211fec8e32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.78      0.70      0.74        10\n",
      "        pass       0.96      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.94        78\n",
      "   macro avg       0.87      0.84      0.85        78\n",
      "weighted avg       0.93      0.94      0.93        78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Performance\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=[\"fail\", \"pass\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92e3dc53-8120-419a-9464-56711f83271e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"fail\", \"pass\"], yticklabels=[\"fail\", \"pass\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix: Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db7386e9-2a7e-4a3c-b500-b08745932b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.53      0.90      0.67        10\n",
      "        pass       0.98      0.88      0.93        68\n",
      "\n",
      "    accuracy                           0.88        78\n",
      "   macro avg       0.76      0.89      0.80        78\n",
      "weighted avg       0.93      0.88      0.90        78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Performance\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=[\"fail\", \"pass\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9193be-0ff5-4bca-ae22-ac021108d6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 13:43:48.063042: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750945428.264536    7770 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750945428.334420    7770 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750945428.990470    7770 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750945428.990506    7770 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750945428.990509    7770 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750945428.990512    7770 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 13:43:52.022158: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.8804 - val_loss: 1.9559\n",
      "Epoch 2/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8367 - val_loss: 1.7919\n",
      "Epoch 3/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5139 - val_loss: 1.6829\n",
      "Epoch 4/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5482 - val_loss: 1.5804\n",
      "Epoch 5/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3851 - val_loss: 1.5069\n",
      "Epoch 6/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3201 - val_loss: 1.4431\n",
      "Epoch 7/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2239 - val_loss: 1.3926\n",
      "Epoch 8/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2644 - val_loss: 1.3479\n",
      "Epoch 9/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2180 - val_loss: 1.3112\n",
      "Epoch 10/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1697 - val_loss: 1.2839\n",
      "Epoch 11/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1283 - val_loss: 1.2523\n",
      "Epoch 12/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1252 - val_loss: 1.2324\n",
      "Epoch 13/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1087 - val_loss: 1.2151\n",
      "Epoch 14/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0670 - val_loss: 1.2016\n",
      "Epoch 15/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0419 - val_loss: 1.1876\n",
      "Epoch 16/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0134 - val_loss: 1.1711\n",
      "Epoch 17/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0234 - val_loss: 1.1600\n",
      "Epoch 18/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0153 - val_loss: 1.1515\n",
      "Epoch 19/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9765 - val_loss: 1.1401\n",
      "Epoch 20/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9920 - val_loss: 1.1325\n",
      "Epoch 21/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9703 - val_loss: 1.1230\n",
      "Epoch 22/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9672 - val_loss: 1.1154\n",
      "Epoch 23/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9617 - val_loss: 1.1099\n",
      "Epoch 24/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9431 - val_loss: 1.1041\n",
      "Epoch 25/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9043 - val_loss: 1.0982\n",
      "Epoch 26/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9589 - val_loss: 1.0922\n",
      "Epoch 27/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9257 - val_loss: 1.0856\n",
      "Epoch 28/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9101 - val_loss: 1.0786\n",
      "Epoch 29/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9081 - val_loss: 1.0697\n",
      "Epoch 30/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8647 - val_loss: 1.0602\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Autoencoder Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.00      0.00      0.00        48\n",
      "        pass       0.87      0.95      0.91       339\n",
      "\n",
      "    accuracy                           0.83       387\n",
      "   macro avg       0.44      0.48      0.45       387\n",
      "weighted avg       0.76      0.83      0.80       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Prepare data for AE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_ae = StandardScaler()\n",
    "X_scaled = scaler_ae.fit_transform(X)            # scale all features\n",
    "X_train_ae = X_scaled[y == 1]                    # train only on pass jobs\n",
    "\n",
    "# 2) Build AE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_dim = X_train_ae.shape[1]\n",
    "encoding_dim = max(2, input_dim // 2)\n",
    "\n",
    "ae = models.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    layers.Dense(encoding_dim, activation=\"relu\"),\n",
    "    layers.Dense(input_dim, activation=\"linear\")\n",
    "])\n",
    "ae.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# 3) Train AE\n",
    "history = ae.fit(\n",
    "    X_train_ae, X_train_ae,\n",
    "    epochs=30,\n",
    "    batch_size=8,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4) Compute reconstruction error\n",
    "recon = ae.predict(X_scaled)\n",
    "mse = np.mean((X_scaled - recon)**2, axis=1)\n",
    "df[\"recon_err\"] = mse\n",
    "\n",
    "# 5) Choose threshold and predict anomalies\n",
    "thr = np.percentile(df.loc[y == 1, \"recon_err\"], 95)\n",
    "df[\"ae_pred\"] = (df[\"recon_err\"] > thr).astype(int)  # 1 = anomaly (fail)\n",
    "df[\"ae_pred\"] = df[\"ae_pred\"].map({1: 0, 0: 1})       # align: 1=pass, 0=fail\n",
    "\n",
    "# 6) Evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Autoencoder Performance\")\n",
    "print(classification_report(y, df[\"ae_pred\"], target_names=[\"fail\",\"pass\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8a2575-7780-4fb2-94c7-398e6bdaddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['timestamp', 'cpu_pct_avg', 'status', 'pipeline_id', 'mode', 'hour', 'dayofweek', 'mem_mb', 'log_duration', 'tag_code', 'recon_err', 'ae_pred']\n"
     ]
    }
   ],
   "source": [
    "#print(df.columns)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fe061a4-9aa2-4fda-89ae-9008303003ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,489</span> (5.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,489\u001b[0m (5.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,489</span> (5.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,489\u001b[0m (5.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7026 - loss: 0.6802 - val_accuracy: 0.6000 - val_loss: 0.6663\n",
      "Epoch 2/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6119 - loss: 0.6616 - val_accuracy: 0.6000 - val_loss: 0.6180\n",
      "Epoch 3/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6332 - loss: 0.6133 - val_accuracy: 0.8000 - val_loss: 0.5916\n",
      "Epoch 4/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6878 - loss: 0.5782 - val_accuracy: 0.7333 - val_loss: 0.5634\n",
      "Epoch 5/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7864 - loss: 0.5390 - val_accuracy: 0.7333 - val_loss: 0.5421\n",
      "Epoch 6/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7158 - loss: 0.5273 - val_accuracy: 0.7333 - val_loss: 0.5237\n",
      "Epoch 7/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7412 - loss: 0.5181 - val_accuracy: 0.7333 - val_loss: 0.5069\n",
      "Epoch 8/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7726 - loss: 0.4678 - val_accuracy: 0.7333 - val_loss: 0.4893\n",
      "Epoch 9/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7521 - loss: 0.4709 - val_accuracy: 0.7333 - val_loss: 0.4821\n",
      "Epoch 10/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7431 - loss: 0.4478 - val_accuracy: 0.7333 - val_loss: 0.4670\n",
      "Epoch 11/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7732 - loss: 0.5245 - val_accuracy: 0.7333 - val_loss: 0.4737\n",
      "Epoch 12/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7238 - loss: 0.4407 - val_accuracy: 0.7333 - val_loss: 0.4681\n",
      "Epoch 13/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7697 - loss: 0.4183 - val_accuracy: 0.7333 - val_loss: 0.4662\n",
      "Epoch 14/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7644 - loss: 0.4504 - val_accuracy: 0.7333 - val_loss: 0.4619\n",
      "Epoch 15/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7561 - loss: 0.4555 - val_accuracy: 0.7333 - val_loss: 0.4526\n",
      "Epoch 16/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7832 - loss: 0.4198 - val_accuracy: 0.7333 - val_loss: 0.4470\n",
      "Epoch 17/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8187 - loss: 0.4108 - val_accuracy: 0.7333 - val_loss: 0.4424\n",
      "Epoch 18/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6618 - loss: 0.5117 - val_accuracy: 0.7333 - val_loss: 0.4361\n",
      "Epoch 19/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8706 - loss: 0.3743 - val_accuracy: 0.7333 - val_loss: 0.4489\n",
      "Epoch 20/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7092 - loss: 0.5200 - val_accuracy: 0.7333 - val_loss: 0.4364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "LSTM Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       1.00      0.56      0.71         9\n",
      "        pass       0.60      1.00      0.75         6\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.80      0.78      0.73        15\n",
      "weighted avg       0.84      0.73      0.73        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1) Build sequences\n",
    "seq_len = 3\n",
    "features = [\"log_duration\", \"cpu_pct_avg\", \"mem_mb\", \"tag_code\"]\n",
    "pipelines = []\n",
    "labels = []\n",
    "\n",
    "for pid, group in df.reset_index().groupby(\"pipeline_id\"):\n",
    "    grp = group.sort_values(\"timestamp\")\n",
    "    feats = grp[features].values\n",
    "    lbls = grp[\"status\"].values\n",
    "    # take the last status as pipeline label (fail if any job failed)\n",
    "    pipeline_label = int((lbls == 1).all())\n",
    "    # pad or truncate to seq_len\n",
    "    if feats.shape[0] < seq_len:\n",
    "        pad = np.zeros((seq_len - feats.shape[0], feats.shape[1]))\n",
    "        feats = np.vstack([feats, pad])\n",
    "    else:\n",
    "        feats = feats[:seq_len]\n",
    "    pipelines.append(feats)\n",
    "    labels.append(pipeline_label)\n",
    "\n",
    "X_seq = np.stack(pipelines)    # shape: (n_pipelines, seq_len, n_features)\n",
    "y_seq = np.array(labels)\n",
    "\n",
    "# 2) Train/test split on pipelines\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq)\n",
    "\n",
    "# 3) Build LSTM model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(seq_len, len(features))),\n",
    "    layers.LSTM(16, return_sequences=False),\n",
    "    layers.Dense(8, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# 4) Train LSTM\n",
    "history = model.fit(\n",
    "    X_tr, y_tr,\n",
    "    validation_data=(X_te, y_te),\n",
    "    epochs=20,\n",
    "    batch_size=4,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 5) Evaluate\n",
    "y_pred_seq = (model.predict(X_te) > 0.5).astype(int).flatten()\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"LSTM Performance\")\n",
    "print(classification_report(y_te, y_pred_seq, target_names=[\"fail\",\"pass\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a8daef-6942-45b0-8beb-340204746a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_pct_avg     → 0.424\n",
      "mem_mb          → 0.197\n",
      "log_duration    → 0.158\n",
      "hour            → 0.128\n",
      "tag_code        → 0.054\n",
      "dayofweek       → 0.040\n"
     ]
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "for feat, score in sorted(zip(features, importances), key=lambda x: -x[1]):\n",
    "    print(f\"{feat:15} → {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "333309c8-b617-4868-9541-95f6d63e6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Save Random Forest model\n",
    "joblib.dump(rf, \"models/rf_model.joblib\")\n",
    "\n",
    "# 2. Fit & save scaler (only if you scaled RF inputs)\n",
    "scaler_rf = StandardScaler().fit(X_train)\n",
    "joblib.dump(scaler_rf, \"models/rf_scaler.joblib\")\n",
    "\n",
    "# 3. Save LSTM in new format\n",
    "model.save(\"models/lstm_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c3a2d-bb77-4c64-8d57-c88ef5c5f103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
