#.gitlab-ci.yml - for merge_incremental

stages:
  - build
  - lint
  - test
  - collect_logs

variables:
  PYTHONDONTWRITEBYTECODE: "1"
  PYTHONUNBUFFERED:       "1"
  POSTGRES_DB:            "bidshopping"
  POSTGRES_USER:          "postgres"
  POSTGRES_PASSWORD:      "postgres"
  DATABASE_URL:           "postgres://postgres:postgres@db:5432/bidshopping"
  STATIC_ROOT:            "/tmp/static"
  DOCKER_TLS_CERTDIR:     ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
build-image:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" "$CI_REGISTRY"
    - docker build -t "$CI_REGISTRY_IMAGE/bidshopping:dev" .
    - docker push "$CI_REGISTRY_IMAGE/bidshopping:dev"
  only:
    - main

image: "$CI_REGISTRY_IMAGE/bidshopping:dev"
services:
  - name: postgres:13
    alias: db

cache:
  paths:
    - .cache/pip

before_script:
  - mkdir -p "$STATIC_ROOT"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

lint:
  stage: lint
  script:
    - flake8 .

test:
  stage: test
  script:
    # 1) collectstatic & migrate â€” bail if these fail
    - python manage.py collectstatic --noinput
    - python manage.py migrate --noinput
    # 2) run unit tests (capture nonâ€‘zero but don't abort)
    - |
      python ci/ci_logger.py \
        "coverage run --source=. manage.py test --parallel --exclude-tag=functional" || \
      echo "unitâ€‘tests failed (captured)"
    # 3) start server for functional tests
    - python manage.py runserver 0.0.0.0:8000 &
    - sleep 5
    # 4) run functional tests (also don't abort)
    - |
      python ci/ci_logger.py \
        "coverage run --append --source=. manage.py test --tag=functional" || \
      echo "functionalâ€‘tests failed (captured)"
    # 5) coverage report (donâ€™t fail the job if coverage is low)
    - coverage report || true
  artifacts:
    when: always
    paths:
      - htmlcov/
      - functional_tests/screenshots/
      - logs/ci_logs.csv
    expire_in: 1 week

# ðŸ“¥ Download and merge incrementally
update-logs:
  stage: collect_logs
  image: python:3.10
  needs: [test]
  before_script:
    - pip install pandas requests
  script:
    # 1) Copy this pipeline's log into data/raw/
    - mkdir -p data/raw
    - cp logs/ci_logs.csv data/raw/${CI_PIPELINE_ID}.csv
    # 2) Merge it into data/all_logs.csv
    - python scripts/merge_incremental.py
    # 3) Push back to GitHub via your existing push_to_github.py
    - echo ">>>> Pushing updated all_logs.csv to GitHub"
    - python scripts/push_to_github.py
  only:
    - main
  except:
    - schedules

# ðŸ§¼ Full refresh from all raw logs â€” used for scheduled jobs
collect-logs:
  stage: collect_logs
  image: python:3.10
  before_script:
    - pip install requests pandas
  script:
    - python scripts/download_logs.py
    - python scripts/merge_full.py
    - echo ">>> Pushing merged CSV via GitHub API"
    - pip install requests
    - python scripts/push_to_github.py
  only:
    - schedules